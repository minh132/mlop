{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold , cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, roc_auc_score,recall_score\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet('raw_train.parquet')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1     object\n",
      "feature2     object\n",
      "feature3     object\n",
      "feature4      int64\n",
      "feature5     object\n",
      "feature6     object\n",
      "feature7      int64\n",
      "feature8     object\n",
      "feature9     object\n",
      "feature10    object\n",
      "feature11     int64\n",
      "feature12     int64\n",
      "feature13     int64\n",
      "label         int64\n",
      "feature14    object\n",
      "feature15    object\n",
      "feature16    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "categorical_features = ['feature3', 'feature5','feature6','feature8','feature9','feature10','feature14','feature15','feature16']\n",
    "\n",
    "# Convert real number values to strings in categorical features\n",
    "df[categorical_features] = df[categorical_features].astype(str)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "# Plot biểu đồ cột\n",
    "label_counts.plot(kind='bar')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Label Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features_config.json', 'r') as f:\n",
    "    features_config = json.load(f)\n",
    "features_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('label',axis=1)\n",
    "# for col in X.columns:\n",
    "#     col_type = X[col].dtype\n",
    "#     if col_type == 'object' or col_type.name == 'category':\n",
    "#         X[col] = X[col].astype('category')\n",
    "# X.columns = [re.sub(r'\\W+', '', col) for col in X.columns]\n",
    "Y=df['label']\n",
    "print(X.dtypes)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    113145\n",
      "1      7635\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = Y_train.value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12559\n",
      "1      862\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts_test = Y_test.value_counts()\n",
    "print(label_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score 0.9787655629696972\n",
      "f1_score 0.9583333333333333\n",
      "recall_score 0.9561200923787528\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(random_state=0,scale_pos_weight=3)\n",
    "\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "Y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"auc_score\",roc_auc_score(Y_test,Y_pred_xgb))\n",
    "print(\"f1_score\",f1_score(Y_pred_xgb,Y_test))\n",
    "print(\"recall_score\",recall_score(Y_pred_xgb,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'prob_1.ckpt'\n",
    "pickle.dump(xgb_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8225d33bea084346b644d9249c216b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f7be6766a70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    # random_seed=42,\n",
    "    # learning_rate=0.1,\n",
    "    # custom_loss=['AUC'],\n",
    "    # scale_pos_weight=5\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, Y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_test, Y_test),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score 0.9576621548148886\n",
      "f1 socre 0.9405469678953626\n",
      "recall 0.9646341463414634\n"
     ]
    }
   ],
   "source": [
    "Y_pred_cb = clf.predict(X_test)\n",
    "print(\"auc_score\",roc_auc_score(Y_test,Y_pred_cb))\n",
    "print(\"f1 socre\", f1_score(Y_pred_cb,Y_test))\n",
    "print(\"recall\",recall_score(Y_pred_cb,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbmc_model=LGBMClassifier(random_state=0,scale_pos_weight=3)\n",
    "lgbmc_model.fit(X_train, Y_train,categorical_feature = 'auto',eval_set=(X_val, Y_val),feature_name='auto', verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "Y_pred_lgbmc = lgbmc_model.predict(X_test)\n",
    "print(\"auc_score\",roc_auc_score(Y_test,Y_pred_lgbmc))\n",
    "print('f1_score',f1_score(Y_test,Y_pred_lgbmc))\n",
    "print(\"recall\",recall_score(Y_test,Y_pred_lgbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'prob_1.ckpt'\n",
    "pickle.dump(lgbmc_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DropColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns = []):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Perform arbitary transformation\n",
    "        X = X.drop(columns=self.columns)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "           (\"scaler\", StandardScaler()),\n",
    "           ('pca', PCA())\n",
    "           ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        # (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, features_config['numeric_columns']),\n",
    "        (\"cat\", categorical_transformer, features_config['category_columns']),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"model\", LGBMClassifier(random_state=0,scale_pos_weight=10))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score 0.9690005170952732\n",
      "f1_score 0.8623757195185766\n",
      "recall 0.9559164733178654\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'model__max_depth': [2, 3, 5, 7],\n",
    "    'model__n_estimators': [10, 25, 50],       \n",
    "}\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "Y_pred_lgbmc = best_model.predict(X_test)\n",
    "print(\"auc_score\",roc_auc_score(Y_test,Y_pred_lgbmc))\n",
    "print('f1_score',f1_score(Y_test,Y_pred_lgbmc))\n",
    "print(\"recall\",recall_score(Y_test,Y_pred_lgbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('preprocessor', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler', StandardScaler()),\n",
      "                                                 ('pca', PCA())]),\n",
      "                                 ['feature3', 'feature4', 'feature5',\n",
      "                                  'feature6', 'feature7', 'feature8',\n",
      "                                  'feature9', 'feature10', 'feature11',\n",
      "                                  'feature12', 'feature13', 'feature14',\n",
      "                                  'feature15', 'feature16']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('encoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 ['feature2', 'feature1'])])), ('model', LGBMClassifier(random_state=0, scale_pos_weight=10))], 'verbose': False, 'preprocessor': ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler', StandardScaler()),\n",
      "                                                 ('pca', PCA())]),\n",
      "                                 ['feature3', 'feature4', 'feature5',\n",
      "                                  'feature6', 'feature7', 'feature8',\n",
      "                                  'feature9', 'feature10', 'feature11',\n",
      "                                  'feature12', 'feature13', 'feature14',\n",
      "                                  'feature15', 'feature16']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('encoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 ['feature2', 'feature1'])]), 'model': LGBMClassifier(random_state=0, scale_pos_weight=10), 'preprocessor__n_jobs': None, 'preprocessor__remainder': 'drop', 'preprocessor__sparse_threshold': 0.3, 'preprocessor__transformer_weights': None, 'preprocessor__transformers': [('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                ('scaler', StandardScaler()), ('pca', PCA())]), ['feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9', 'feature10', 'feature11', 'feature12', 'feature13', 'feature14', 'feature15', 'feature16']), ('cat', Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))]), ['feature2', 'feature1'])], 'preprocessor__verbose': False, 'preprocessor__verbose_feature_names_out': True, 'preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                ('scaler', StandardScaler()), ('pca', PCA())]), 'preprocessor__cat': Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))]), 'preprocessor__num__memory': None, 'preprocessor__num__steps': [('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler()), ('pca', PCA())], 'preprocessor__num__verbose': False, 'preprocessor__num__imputer': SimpleImputer(strategy='median'), 'preprocessor__num__scaler': StandardScaler(), 'preprocessor__num__pca': PCA(), 'preprocessor__num__imputer__add_indicator': False, 'preprocessor__num__imputer__copy': True, 'preprocessor__num__imputer__fill_value': None, 'preprocessor__num__imputer__keep_empty_features': False, 'preprocessor__num__imputer__missing_values': nan, 'preprocessor__num__imputer__strategy': 'median', 'preprocessor__num__imputer__verbose': 'deprecated', 'preprocessor__num__scaler__copy': True, 'preprocessor__num__scaler__with_mean': True, 'preprocessor__num__scaler__with_std': True, 'preprocessor__num__pca__copy': True, 'preprocessor__num__pca__iterated_power': 'auto', 'preprocessor__num__pca__n_components': None, 'preprocessor__num__pca__n_oversamples': 10, 'preprocessor__num__pca__power_iteration_normalizer': 'auto', 'preprocessor__num__pca__random_state': None, 'preprocessor__num__pca__svd_solver': 'auto', 'preprocessor__num__pca__tol': 0.0, 'preprocessor__num__pca__whiten': False, 'preprocessor__cat__memory': None, 'preprocessor__cat__steps': [('encoder', OneHotEncoder(handle_unknown='ignore'))], 'preprocessor__cat__verbose': False, 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore'), 'preprocessor__cat__encoder__categories': 'auto', 'preprocessor__cat__encoder__drop': None, 'preprocessor__cat__encoder__dtype': <class 'numpy.float64'>, 'preprocessor__cat__encoder__handle_unknown': 'ignore', 'preprocessor__cat__encoder__max_categories': None, 'preprocessor__cat__encoder__min_frequency': None, 'preprocessor__cat__encoder__sparse': 'deprecated', 'preprocessor__cat__encoder__sparse_output': True, 'model__boosting_type': 'gbdt', 'model__class_weight': None, 'model__colsample_bytree': 1.0, 'model__importance_type': 'split', 'model__learning_rate': 0.1, 'model__max_depth': -1, 'model__min_child_samples': 20, 'model__min_child_weight': 0.001, 'model__min_split_gain': 0.0, 'model__n_estimators': 100, 'model__n_jobs': -1, 'model__num_leaves': 31, 'model__objective': None, 'model__random_state': 0, 'model__reg_alpha': 0.0, 'model__reg_lambda': 0.0, 'model__silent': 'warn', 'model__subsample': 1.0, 'model__subsample_for_bin': 200000, 'model__subsample_freq': 0, 'model__scale_pos_weight': 10}\n",
      "auc_score 0.974050601809113\n",
      "f1_score 0.8904403866809881\n",
      "recall 0.9617169373549884\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)\n",
    "print(clf.get_params())\n",
    "Y_pred_lgbmc = clf.predict(X_test)\n",
    "print(\"auc_score\",roc_auc_score(Y_test,Y_pred_lgbmc))\n",
    "print('f1_score',f1_score(Y_test,Y_pred_lgbmc))\n",
    "print(\"recall\",recall_score(Y_test,Y_pred_lgbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'prob_1.ckpt'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
